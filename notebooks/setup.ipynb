{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nasifnur307-blip/biomarkerlink/blob/main/notebooks/setup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy scipy matplotlib scikit-learn pandas networkx pgmpy causal-learn\n"
      ],
      "metadata": {
        "id": "6YmjMjCEHeqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d2a924b-7423-4b95-c5cf-6448cc47d8e6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (3.6)\n",
            "Requirement already satisfied: pgmpy in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: causal-learn in /usr/local/lib/python3.12/dist-packages (0.1.4.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pgmpy) (2.9.0+cu126)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from pgmpy) (0.14.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pgmpy) (4.67.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.12/dist-packages (from pgmpy) (3.4.0)\n",
            "Requirement already satisfied: pyro-ppl in /usr/local/lib/python3.12/dist-packages (from pgmpy) (1.9.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from causal-learn) (0.21)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (from causal-learn) (4.0.1)\n",
            "Requirement already satisfied: momentchi2 in /usr/local/lib/python3.12/dist-packages (from causal-learn) (0.1.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from pyro-ppl->pgmpy) (0.1.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (1.14.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->pgmpy) (3.5.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->pgmpy) (1.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->pgmpy) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pgmpy) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install causal-learn==0.1.4.3\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK7bRUcNpoDu",
        "outputId": "b8de4ac4-3511-4dcd-d056-05a2b2696aab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: causal-learn==0.1.4.3 in /usr/local/lib/python3.12/dist-packages (0.1.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (1.6.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (0.21)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (0.14.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (3.10.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (3.6)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (4.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (4.67.1)\n",
            "Requirement already satisfied: momentchi2 in /usr/local/lib/python3.12/dist-packages (from causal-learn==0.1.4.3) (0.1.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn==0.1.4.3) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn==0.1.4.3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn==0.1.4.3) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn==0.1.4.3) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn==0.1.4.3) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn==0.1.4.3) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn==0.1.4.3) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->causal-learn==0.1.4.3) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->causal-learn==0.1.4.3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->causal-learn==0.1.4.3) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->causal-learn==0.1.4.3) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->causal-learn==0.1.4.3) (3.6.0)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels->causal-learn==0.1.4.3) (1.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->causal-learn==0.1.4.3) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lowercase causallearn\n",
        "from causallearn.search.ConstraintBased.PC import pc\n"
      ],
      "metadata": {
        "id": "Vm_XDkyQqH6x"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n"
      ],
      "metadata": {
        "id": "OUxtQGhOi8to"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from causallearn.search.ConstraintBased.PC import pc\n",
        "\n",
        "print(\"Ready.\")\n"
      ],
      "metadata": {
        "id": "VnKJxP7aHfk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37173e5-4646-4fd7-c071-3bad9ae2dcfd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/nasifnur307-blip/biomarkerlink.git\n"
      ],
      "metadata": {
        "id": "h2_Xsy6uHpAm",
        "outputId": "2934a07c-061d-464c-a445-ffcb9a3e0019",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "fatal: destination path 'biomarkerlink' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "folders = [\n",
        "    \"data/raw\",\n",
        "    \"data/processed\",\n",
        "    \"results/graphs\",\n",
        "    \"results/models\",\n",
        "]\n",
        "\n",
        "for f in folders:\n",
        "    os.makedirs(f, exist_ok=True)\n",
        "\n",
        "print(\"Folders created.\")\n"
      ],
      "metadata": {
        "id": "ftHUJtzWICQU",
        "outputId": "2b2caa28-311c-4084-801b-de3b31fd4bb8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/NeuroFedMeta/data/CHBMIT/chbmit_preprocessed_data.csv')\n",
        "\n",
        "print(\"Dataset shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(\"Label distribution:\\n\", df['Outcome'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHkiZMJQdeRN",
        "outputId": "f2d0cb1d-bff2-485e-9110-68b6353a9144"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset shape: (2097150, 24)\n",
            "Columns: ['# FP1-F7', 'C3-P3', 'C4-P4', 'CZ-PZ', 'F3-C3', 'F4-C4', 'F7-T7', 'F8-T8', 'FP1-F3', 'FP2-F4', 'FP2-F8', 'FT10-T8', 'FT9-FT10', 'FZ-CZ', 'P3-O1', 'P4-O2', 'P7-O1', 'P7-T7', 'P8-O2', 'T7-FT9', 'T7-P7', 'T8-P8-0', 'T8-P8-1', 'Outcome']\n",
            "Label distribution:\n",
            " Outcome\n",
            "0.0    1048575\n",
            "1.0    1048575\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features = EEG channels (first 23 columns)\n",
        "X = df.iloc[:, :-1].values\n",
        "# Outcome column = inter-/pre-/ictal labels\n",
        "y = df['Outcome'].values\n",
        "\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Labels shape:\", y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp5rZ_LBeiXQ",
        "outputId": "409f988d-b1f5-4874-879e-16a6538e45e8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features shape: (2097150, 23)\n",
            "Labels shape: (2097150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n"
      ],
      "metadata": {
        "id": "rJkPMyDnePkx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inter-ictal: Outcome = 0\n",
        "X_inter = X_scaled[y == 0]\n",
        "\n",
        "# Pre-ictal: Outcome = 1 (adjust if you have explicit pre-ictal vs ictal labels)\n",
        "X_pre = X_scaled[y == 1]\n",
        "\n",
        "print(\"Inter-ictal shape:\", X_inter.shape)\n",
        "print(\"Pre-ictal shape:\", X_pre.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxThOGnVjFS5",
        "outputId": "f8079c49-892b-467d-f41c-ab4c319ee381"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inter-ictal shape: (1048575, 23)\n",
            "Pre-ictal shape: (1048575, 23)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "alpha = 0.05\n",
        "\n",
        "\n",
        "is_identical = df[df.columns[-3]].equals(df[df.columns[-2]])\n",
        "print(f\"Are columns '{df.columns[-3]}' and '{df.columns[-2]}' identical? {is_identical}\")\n",
        "\n",
        "if is_identical:\n",
        "    print(f\"Dropping column '{df.columns[-2]}' due to duplication.\")\n",
        "    # Re-extract features, excluding the duplicate column\n",
        "    features_to_use = [col for col in df.columns[:-1] if col != df.columns[-2]]\n",
        "    X_fixed = df[features_to_use].values\n",
        "\n",
        "\n",
        "    scaler_fixed = StandardScaler()\n",
        "    X_scaled_fixed = scaler_fixed.fit_transform(X_fixed)\n",
        "\n",
        "\n",
        "    X_inter_fixed = X_scaled_fixed[y == 0]\n",
        "    X_pre_fixed = X_scaled_fixed[y == 1]\n",
        "\n",
        "    print(\"Running PC algorithm with fixed data...\")\n",
        "    causal_graph_inter = pc(data=X_inter_fixed, alpha=alpha, method_ind='hsic')\n",
        "else:\n",
        "    print(\"Columns are not identical, running PC with original data...\")\n",
        "    causal_graph_inter = pc(data=X_inter, alpha=alpha, method_ind='hsic')\n",
        "\n",
        "\n",
        "print(\"PC algorithm finished for inter-ictal state.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "b26af63e40e24a59a20ac00b40efe4a6",
            "60d2933769bf467ebb5566513d795b20",
            "7b22f780112541f4b83887883aacde14",
            "24d14248214e42659246e9e11a3273fd",
            "db0b386e79384e7d926f7f51dcc26ee7",
            "91478f95a9f84f35aa391f92e1c3c9fe",
            "127f23687699495e884e3b4b59153c16",
            "0cd4aede489049c7a4e1eaf9aea4d11e",
            "8084bec3f659430f9b2e1400207adabd",
            "ff82a00ecb1646ce9b0a05bd651f3e79",
            "022ecb026fcd4654a80fe46b566fb01c"
          ]
        },
        "id": "wUMPIzngjOMP",
        "outputId": "296db35e-5814-4b70-a916-df51bdc93950"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Are columns 'T8-P8-0' and 'T8-P8-1' identical? True\n",
            "Dropping column 'T8-P8-1' due to duplication.\n",
            "Running PC algorithm with fixed data...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b26af63e40e24a59a20ac00b40efe4a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PC algorithm finished for inter-ictal state.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6CHYDSJQsm9D"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.1 # Increased alpha value\n",
        "causal_graph_inter = pc(data=X_inter_fixed, alpha=alpha, method_ind='hsic')\n",
        "print(\"PC algorithm finished for inter-ictal state.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ec985a930caf482ebbdfdf6615e67938",
            "e4ba767756164253be11a16b8f1555d4",
            "420844059e00411992a75d068ace00da",
            "3c8069123e7c41d7aa8766091fa8f2fa",
            "1e42ab823329465285f8f15d6b71090b",
            "5bf21bcfc1a54ce999ac66f5b806dd7c",
            "e6cc8cf1fcda4318830f212f8985056e",
            "7893d85e3b33441b885d9bb451fe8f01",
            "a004f83bd7ac418f86226ca04a80c754",
            "cc823ba0c84d4330b6d0ca2b92504029",
            "ab0f6027a19047ce80ce72e8c8247791"
          ]
        },
        "id": "VnYvldakq2GC",
        "outputId": "3ffa7c52-1f9b-45cf-db24-46dfa5ab534a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/22 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec985a930caf482ebbdfdf6615e67938"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PC algorithm finished for inter-ictal state.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "G = nx.DiGraph()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "32Xn-jtOtC84"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cf1932bf",
        "outputId": "6d53ed93-0ed8-4650-caba-5c57c5d8f1fd"
      },
      "source": [
        "# Get the NetworkX graph directly from the CausalGraph object\n",
        "G = causal_graph_inter.to_nx_graph()\n",
        "\n",
        "# Get the feature names from the original dataframe, excluding the 'Outcome' and the dropped duplicate column\n",
        "# This assumes 'df' is still available and the duplicate column handling was consistent\n",
        "if 'T8-P8-1' in df.columns:\n",
        "    feature_names = [col for col in df.columns[:-1] if col != 'T8-P8-1']\n",
        "else:\n",
        "    feature_names = df.columns[:-1].tolist()\n",
        "\n",
        "# Check if a graph was actually generated\n",
        "if G is None:\n",
        "    print(\"No causal graph could be generated or the graph is empty.\")\n",
        "else:\n",
        "    # Create a mapping for relabeling nodes if feature names are different from original indices\n",
        "    # Ensure the number of feature names matches the number of nodes in the graph\n",
        "    if len(feature_names) == G.number_of_nodes():\n",
        "        mapping = {i: name for i, name in enumerate(feature_names)}\n",
        "        G = nx.relabel_nodes(G, mapping)\n",
        "    else:\n",
        "        print(\"Warning: Number of feature names does not match number of nodes in the graph. Skipping relabeling.\")\n",
        "\n",
        "    # Plot the graph\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    pos = nx.spring_layout(G) # You can try other layouts like circular_layout, shell_layout\n",
        "    nx.draw_networkx_nodes(G, pos, node_size=700, node_color='lightblue')\n",
        "    nx.draw_networkx_edges(G, pos, arrowstyle='->', arrowsize=20, edge_color='gray')\n",
        "    nx.draw_networkx_labels(G, pos, font_size=8)\n",
        "    plt.title('Causal Graph for Inter-ictal State')\n",
        "    plt.axis('off') # Hide axes\n",
        "    plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No causal graph could be generated or the graph is empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "527464f2",
        "outputId": "82a6e05d-d87d-4f3f-80dd-8aa73a3de19c"
      },
      "source": [
        "# Get the NetworkX skeleton (undirected graph) from the CausalGraph object\n",
        "G_skel = causal_graph_inter.to_nx_skeleton()\n",
        "\n",
        "# Get the feature names from the original dataframe, excluding the 'Outcome' and the dropped duplicate column\n",
        "# This assumes 'df' is still available and the duplicate column handling was consistent\n",
        "if 'T8-P8-1' in df.columns:\n",
        "    feature_names = [col for col in df.columns[:-1] if col != 'T8-P8-1']\n",
        "else:\n",
        "    feature_names = df.columns[:-1].tolist()\n",
        "\n",
        "# Check if a skeleton was actually generated\n",
        "if G_skel is None:\n",
        "    print(\"No causal graph skeleton could be generated or the skeleton is empty.\")\n",
        "else:\n",
        "    # Create a mapping for relabeling nodes if feature names are different from original indices\n",
        "    if len(feature_names) == G_skel.number_of_nodes():\n",
        "        mapping = {i: name for i, name in enumerate(feature_names)}\n",
        "        G_skel = nx.relabel_nodes(G_skel, mapping)\n",
        "    else:\n",
        "        print(\"Warning: Number of feature names does not match number of nodes in the skeleton. Skipping relabeling.\")\n",
        "\n",
        "    # Plot the skeleton\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    pos = nx.spring_layout(G_skel) # You can try other layouts like circular_layout, shell_layout\n",
        "    nx.draw_networkx_nodes(G_skel, pos, node_size=700, node_color='lightcoral')\n",
        "    nx.draw_networkx_edges(G_skel, pos, edge_color='gray') # No arrows for undirected graph\n",
        "    nx.draw_networkx_labels(G_skel, pos, font_size=8)\n",
        "    plt.title('Causal Graph Skeleton for Inter-ictal State (Undirected Associations)')\n",
        "    plt.axis('off') # Hide axes\n",
        "    plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No causal graph skeleton could be generated or the skeleton is empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be497ca8",
        "outputId": "cbdd706c-0300-48d8-d0da-9ec2d58b435a"
      },
      "source": [
        "print(type(causal_graph_inter))\n",
        "print(dir(causal_graph_inter))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'causallearn.graph.GraphClass.CausalGraph'>\n",
            "['G', 'PC_elapsed', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__slotnames__', '__str__', '__subclasshook__', '__weakref__', 'ci_test', 'definite_UC', 'definite_non_UC', 'draw_nx_graph', 'draw_pydot_graph', 'find_adj', 'find_arrow_heads', 'find_bi_directed', 'find_cond_sets', 'find_cond_sets_with_mid', 'find_cond_sets_without_mid', 'find_fully_directed', 'find_kites', 'find_tails', 'find_triangles', 'find_undirected', 'find_unshielded_triples', 'is_fully_directed', 'is_undirected', 'labels', 'max_degree', 'neighbors', 'nx_graph', 'nx_skel', 'prt_m', 'rearrange', 'redundant_nodes', 'sepset', 'set_ind_test', 'test', 'to_nx_graph', 'to_nx_skeleton']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12603f51"
      },
      "source": [
        "# Task\n",
        "Investigate why the PC algorithm is not generating a causal graph or skeleton for the inter-ictal state. This includes checking the internal state of the `causal_graph_inter` object (e.g., number of nodes and edges) to understand if the PC algorithm is genuinely finding no causal links with the current preprocessing and alpha level, or if there's an issue with the graph conversion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bba9453"
      },
      "source": [
        "## Evaluate Existing Preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Analyze how the existing preprocessing of the CHBMIT dataset might be affecting the detectability of causal links. This includes considering if important temporal or spectral information was lost, or if normalization/feature extraction methods have obscured dependencies suitable for the PC algorithm. We will discuss the trade-offs between using a preprocessed dataset and raw data for causal inference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "965cf1a4"
      },
      "source": [
        "## Analyze Existing Preprocessing Impact on Causal Links\n",
        "\n",
        "This section reviews the current preprocessing applied to the CHBMIT dataset and analyzes its potential implications for the detectability of causal links using the PC algorithm. We will consider how `StandardScaler` and the removal of duplicate columns might affect the underlying data structure relevant for causal inference, and discuss the trade-offs involved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "379572f4"
      },
      "source": [
        "### Review of Preprocessing Steps\n",
        "\n",
        "In the preceding steps, the following preprocessing actions were performed on the CHBMIT dataset:\n",
        "\n",
        "1.  **Data Loading**: The dataset `chbmit_preprocessed_data.csv` was loaded into a Pandas DataFrame `df`.\n",
        "2.  **Feature and Label Separation**: The last column, 'Outcome', was separated as the label `y`, and the remaining columns were designated as features `X`.\n",
        "3.  **Standardization**: The features `X` were standardized using `sklearn.preprocessing.StandardScaler` to `X_scaled`. This transforms the data to have zero mean and unit variance.\n",
        "4.  **Duplicate Column Handling**: A check for identical columns `T8-P8-0` and `T8-P8-1` was performed. Since they were found to be identical, `T8-P8-1` was dropped, and the features were re-extracted and scaled as `X_fixed` and `X_scaled_fixed`.\n",
        "5.  **State Separation**: The data was split into inter-ictal (`y == 0`) and pre-ictal (`y == 1`) states, resulting in `X_inter_fixed` and `X_pre_fixed` (after duplicate column handling).\n",
        "6.  **PC Algorithm Application**: The PC algorithm was applied to `X_inter_fixed` to infer a causal graph.\n",
        "\n",
        "Now we will analyze the implications of these steps for causal inference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc70709b"
      },
      "source": [
        "### Impact of Standardization (`StandardScaler`)\n",
        "\n",
        "**StandardScaler** transforms features to have a mean of 0 and a standard deviation of 1. While beneficial for many machine learning algorithms that assume normally distributed or scaled data, its impact on causal inference can be nuanced:\n",
        "\n",
        "*   **Preservation of Linear Relationships**: Standardization typically preserves linear relationships between variables. If the underlying causal links are linear, `StandardScaler` should not fundamentally alter the conditional independencies necessary for the PC algorithm.\n",
        "*   **Impact on Non-linear Relationships**: For non-linear relationships or tests that are sensitive to the absolute scale of the data, standardization might obscure or amplify certain patterns. However, the `hsic` (Hilbert-Schmidt Independence Criterion) used in the PC algorithm is designed to detect general (including non-linear) dependencies and is generally less sensitive to scaling changes than parametric tests.\n",
        "*   **Variance and Distribution**: By enforcing unit variance, `StandardScaler` removes information about the original scale and spread of each feature. This might be a concern if the absolute magnitude of variability in an EEG channel carries causal information, which is then lost. However, for identifying *conditional independencies*, the relative information content is often more important than absolute scales.\n",
        "*   **Outlier Influence**: Standardization can be sensitive to outliers. While it doesn't remove them, extreme values can disproportionately influence the mean and standard deviation, potentially compressing the range of other data points. If outliers are causally relevant, this transformation could distort their perceived influence.\n",
        "\n",
        "In the context of the PC algorithm, which relies on conditional independence tests, `StandardScaler` is generally considered acceptable as long as the independence test itself is robust to scaling (like `hsic`). It ensures that all features contribute equally to distance calculations or similarity measures within the independence test, preventing features with larger scales from dominating."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba695a57"
      },
      "source": [
        "### Impact of Duplicate Column Handling (Removing 'T8-P8-1')\n",
        "\n",
        "**Duplicate column handling** involved identifying and removing 'T8-P8-1' because it was identical to 'T8-P8-0'.\n",
        "\n",
        "*   **Benefits**: Removing truly identical columns is generally a good practice in data analysis and causal inference. Duplicate features provide no new information and can unnecessarily increase computational complexity or introduce redundancy in models. For constraint-based algorithms like PC, having identical features would mean they are perfectly correlated, which could lead to trivial dependencies or issues in independence testing if not handled properly.\n",
        "*   **No Information Loss**: Since the columns were identical, removing one of them does not result in the loss of unique information. The causal relationships that might exist with 'T8-P8-0' are fully preserved, as 'T8-P8-1' was merely a redundant representation of the same signal.\n",
        "*   **Simplification**: It simplifies the causal discovery process by reducing the number of variables the PC algorithm needs to consider, potentially making the resulting graph cleaner and easier to interpret without sacrificing any genuine causal signal.\n",
        "\n",
        "In summary, the removal of 'T8-P8-1' is a benign preprocessing step for causal inference, as it eliminates redundancy without losing any distinct information relevant to the causal structure."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1b3190be"
      },
      "source": [
        "### Potential Loss of Information and Impact on PC Algorithm\n",
        "\n",
        "The current preprocessing steps, while standard, might have implications for specific types of causal links, especially those related to temporal or spectral dynamics:\n",
        "\n",
        "*   **Loss of Temporal Information**: The current dataset `chbmit_preprocessed_data.csv` is presented as a snapshot of features derived from EEG channels. It's unclear from the provided context whether this data retains its inherent temporal sequence or if it has been aggregated (e.g., averaged over time windows, or treated as independent samples). If temporal ordering and dependencies (e.g., X causes Y at a later time point) are crucial for the causal relationships in EEG, and if the data has lost its sequential nature, then the PC algorithm, which typically infers causal graphs from i.i.d. (independent and identically distributed) samples, might struggle to capture these time-lagged causal effects. The PC algorithm implicitly assumes contemporaneous relationships unless explicitly extended for time-series data.\n",
        "\n",
        "*   **Loss of Spectral Information**: Similarly, the feature names (e.g., 'FP1-F7', 'C3-P3') suggest that these are raw or band-filtered EEG channel values. If specific frequency band power or cross-frequency coupling carries causal information, and the preprocessing involved simple amplitude values without explicit spectral decomposition (e.g., into alpha, beta, gamma bands), then this information might not be optimally represented for causal discovery. The `hsic` test can capture general dependencies, but if the causal links are intrinsically spectral, representing them only in the time domain (or simple amplitude domain) might make them harder to detect.\n",
        "\n",
        "*   **Difficulty for PC Algorithm**: The PC algorithm relies on identifying conditional independencies. If the preprocessing has inadvertently transformed causally related variables in a highly non-linear or aggregated manner that obscures these independencies (even if `hsic` is used for non-linear detection), then the PC algorithm might produce a sparse or inaccurate graph. For example, if a causal effect is very weak but consistent over time, and averaging reduces its signal-to-noise ratio, it might fail independence tests.\n",
        "\n",
        "*   **Assumption of i.i.d. Data**: A fundamental assumption of many causal discovery algorithms, including PC, is that the data points are independent and identically distributed (i.i.d.). While we are analyzing two different states (inter-ictal and pre-ictal), within each state, the individual rows of the dataframe are treated as i.i.d. samples. For highly correlated time-series data like EEG, this assumption is often violated. This violation can lead to spurious causal links or an inability to detect true ones. More sophisticated causal inference methods for time series (e.g., Granger causality, VAR models, or extensions of PC for time series) might be required if the temporal structure is critical."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d14fbaad"
      },
      "source": [
        "### Trade-offs: Preprocessed Data vs. Raw Data for Causal Inference\n",
        "\n",
        "Choosing between a preprocessed dataset and raw EEG data for causal inference involves several trade-offs:\n",
        "\n",
        "**Benefits of Using Preprocessed Data (as currently done):**\n",
        "\n",
        "*   **Reduced Noise and Artifacts**: Preprocessing often includes steps like artifact removal (e.g., eye blinks, muscle activity) and noise reduction, leading to cleaner signals. This can improve the signal-to-noise ratio, potentially making true causal effects more detectable and reducing spurious correlations.\n",
        "*   **Dimensionality Reduction/Feature Engineering**: The preprocessed dataset likely represents features that are already aggregated or extracted (e.g., time-averaged EEG channel values). This can simplify the data and reduce the dimensionality, which is beneficial for algorithms like PC that can become computationally expensive with many variables.\n",
        "*   **Standardization**: As discussed, `StandardScaler` ensures features are on a comparable scale, which can prevent features with larger absolute values from dominating conditional independence tests, especially in distance-based measures.\n",
        "*   **Computational Efficiency**: Working with preprocessed, reduced-dimensionality data is significantly faster for causal discovery algorithms compared to raw, high-resolution time series data.\n",
        "\n",
        "**Drawbacks of Using Preprocessed Data for Causal Inference:**\n",
        "\n",
        "*   **Loss of Temporal/Spectral Resolution**: The most significant drawback is the potential loss of critical temporal and spectral information. If causal links manifest as time-lagged effects (e.g., one brain region influencing another milliseconds later) or in specific frequency bands, and the preprocessing flattens or aggregates this information, these causal links may become undetectable.\n",
        "*   **Obscured Non-linearities**: While HSIC is robust, if preprocessing applies strong non-linear transformations or aggregations, it might obscure subtle non-linear causal dependencies that would have been evident in raw data.\n",
        "*   **Assumption of i.i.d. Samples**: Aggregation of time-series data into 'snapshots' forces the assumption of i.i.d. samples, which might violate the temporal autocorrelation inherent in EEG signals, leading to biased causal inferences.\n",
        "*   **Dependence on Preprocessing Choices**: The causal graph inferred is highly dependent on the choices made during preprocessing. If these choices are suboptimal or based on assumptions that don't hold for the causal question, the results can be misleading.\n",
        "\n",
        "**Benefits of Using Raw EEG Data for Causal Inference:**\n",
        "\n",
        "*   **Preservation of Full Information**: Raw data retains all temporal, spectral, and spatial information, allowing for a more comprehensive exploration of potential causal links, including time-lagged effects and frequency-specific interactions.\n",
        "*   **Flexibility for Advanced Causal Models**: Raw data is suitable for advanced causal inference methods designed for time series (e.g., Granger Causality, Dynamic Causal Modeling, or extensions of PC for time series) that can explicitly model temporal dependencies.\n",
        "\n",
        "**Drawbacks of Using Raw EEG Data:**\n",
        "\n",
        "*   **High Dimensionality and Complexity**: Raw EEG data is extremely high-dimensional and noisy, requiring significant computational resources and sophisticated methods to analyze effectively.\n",
        "*   **Increased Risk of Spurious Correlations**: Without proper noise reduction and artifact removal, raw data can lead to many spurious correlations, complicating causal discovery.\n",
        "*   **Difficult to Apply Standard PC Algorithm**: The standard PC algorithm is generally not designed for raw time-series data due to the i.i.d. assumption and high dimensionality, making its direct application problematic.\n",
        "\n",
        "**Conclusion on Trade-offs:**\n",
        "\n",
        "For the current subtask using the provided `chbmit_preprocessed_data.csv` and the PC algorithm, the preprocessing steps are largely acceptable given the tools and data format. `StandardScaler` and duplicate removal are standard and generally benign for conditional independence tests with robust statistics like HSIC. However, it is crucial to acknowledge that the *initial creation* of this preprocessed CSV (which is outside the scope of the current notebook) might have involved significant aggregation or feature extraction that could have already sacrificed critical temporal or spectral information relevant to true underlying causal brain mechanisms. If deeper insights into time-dependent or frequency-specific causal dynamics are required, a move towards raw EEG data combined with time-series-aware causal inference methods would be necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41c6908a"
      },
      "source": [
        "### Trade-offs: Preprocessed Data vs. Raw Data for Causal Inference\n",
        "\n",
        "Choosing between a preprocessed dataset and raw EEG data for causal inference involves several trade-offs:\n",
        "\n",
        "**Benefits of Using Preprocessed Data (as currently done):**\n",
        "\n",
        "*   **Reduced Noise and Artifacts**: Preprocessing often includes steps like artifact removal (e.g., eye blinks, muscle activity) and noise reduction, leading to cleaner signals. This can improve the signal-to-noise ratio, potentially making true causal effects more detectable and reducing spurious correlations.\n",
        "*   **Dimensionality Reduction/Feature Engineering**: The preprocessed dataset likely represents features that are already aggregated or extracted (e.g., time-averaged EEG channel values). This can simplify the data and reduce the dimensionality, which is beneficial for algorithms like PC that can become computationally expensive with many variables.\n",
        "*   **Standardization**: As discussed, `StandardScaler` ensures features are on a comparable scale, which can prevent features with larger absolute values from dominating conditional independence tests, especially in distance-based measures.\n",
        "*   **Computational Efficiency**: Working with preprocessed, reduced-dimensionality data is significantly faster for causal discovery algorithms compared to raw, high-resolution time series data.\n",
        "\n",
        "**Drawbacks of Using Preprocessed Data for Causal Inference:**\n",
        "\n",
        "*   **Loss of Temporal/Spectral Resolution**: The most significant drawback is the potential loss of critical temporal and spectral information. If causal links manifest as time-lagged effects (e.g., one brain region influencing another milliseconds later) or in specific frequency bands, and the preprocessing flattens or aggregates this information, these causal links may become undetectable.\n",
        "*   **Obscured Non-linearities**: While HSIC is robust, if preprocessing applies strong non-linear transformations or aggregations, it might obscure subtle non-linear causal dependencies that would have been evident in raw data.\n",
        "*   **Assumption of i.i.d. Samples**: Aggregation of time-series data into 'snapshots' forces the assumption of i.i.d. samples, which might violate the temporal autocorrelation inherent in EEG signals, leading to biased causal inferences.\n",
        "*   **Dependence on Preprocessing Choices**: The causal graph inferred is highly dependent on the choices made during preprocessing. If these choices are suboptimal or based on assumptions that don't hold for the causal question, the results can be misleading.\n",
        "\n",
        "**Benefits of Using Raw EEG Data for Causal Inference:**\n",
        "\n",
        "*   **Preservation of Full Information**: Raw data retains all temporal, spectral, and spatial information, allowing for a more comprehensive exploration of potential causal links, including time-lagged effects and frequency-specific interactions.\n",
        "*   **Flexibility for Advanced Causal Models**: Raw data is suitable for advanced causal inference methods designed for time series (e.g., Granger Causality, Dynamic Causal Modeling, or extensions of PC for time series) that can explicitly model temporal dependencies.\n",
        "\n",
        "**Drawbacks of Using Raw EEG Data:**\n",
        "\n",
        "*   **High Dimensionality and Complexity**: Raw EEG data is extremely high-dimensional and noisy, requiring significant computational resources and sophisticated methods to analyze effectively.\n",
        "*   **Increased Risk of Spurious Correlations**: Without proper noise reduction and artifact removal, raw data can lead to many spurious correlations, complicating causal discovery.\n",
        "*   **Difficult to Apply Standard PC Algorithm**: The standard PC algorithm is generally not designed for raw time-series data due to the i.i.d. assumption and high dimensionality, making its direct application problematic.\n",
        "\n",
        "**Conclusion on Trade-offs:**\n",
        "\n",
        "For the current subtask using the provided `chbmit_preprocessed_data.csv` and the PC algorithm, the preprocessing steps are largely acceptable given the tools and data format. `StandardScaler` and duplicate removal are standard and generally benign for conditional independence tests with robust statistics like HSIC. However, it is crucial to acknowledge that the *initial creation* of this preprocessed CSV (which is outside the scope of the current notebook) might have involved significant aggregation or feature extraction that could have already sacrificed critical temporal or spectral information relevant to true underlying causal brain mechanisms. If deeper insights into time-dependent or frequency-specific causal dynamics are required, a move towards raw EEG data combined with time-series-aware causal inference methods would be necessary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41a7d28b"
      },
      "source": [
        "## Investigate causal graph properties\n",
        "\n",
        "### Subtask:\n",
        "Investigate why the PC algorithm is not generating a causal graph or skeleton for the inter-ictal state. This includes checking the internal state of the `causal_graph_inter` object (e.g., number of nodes and edges) to understand if the PC algorithm is genuinely finding no causal links with the current preprocessing and alpha level, or if there's an issue with the graph conversion.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6135fef"
      },
      "source": [
        "**Reasoning**:\n",
        "To investigate why the PC algorithm is not generating a causal graph or skeleton, I will check the number of nodes and edges in both the NetworkX graph and skeleton representations derived from the `causal_graph_inter` object. This will help determine if the graph is empty or if there's a problem with the conversion.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46ed4c55",
        "outputId": "d22164f1-f917-4038-d3f8-1452952daa9e"
      },
      "source": [
        "import networkx as nx\n",
        "\n",
        "# 1. Access the underlying NetworkX graph representation\n",
        "inter_graph_nx = causal_graph_inter.to_nx_graph()\n",
        "\n",
        "# 2. Print the number of nodes and edges in inter_graph_nx\n",
        "if inter_graph_nx:\n",
        "    print(f\"Inter-ictal Causal Graph (Directed):\\n  Number of nodes: {inter_graph_nx.number_of_nodes()}\\n  Number of edges: {inter_graph_nx.number_of_edges()}\")\n",
        "else:\n",
        "    print(\"Inter-ictal Causal Graph (Directed): No graph generated or graph is empty.\")\n",
        "\n",
        "# 3. Access the underlying NetworkX skeleton (undirected graph) representation\n",
        "inter_skeleton_nx = causal_graph_inter.to_nx_skeleton()\n",
        "\n",
        "# 4. Print the number of nodes and edges in inter_skeleton_nx\n",
        "if inter_skeleton_nx:\n",
        "    print(f\"Inter-ictal Causal Graph Skeleton (Undirected):\\n  Number of nodes: {inter_skeleton_nx.number_of_nodes()}\\n  Number of edges: {inter_skeleton_nx.number_of_edges()}\")\n",
        "else:\n",
        "    print(\"Inter-ictal Causal Graph Skeleton (Undirected): No skeleton generated or skeleton is empty.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inter-ictal Causal Graph (Directed): No graph generated or graph is empty.\n",
            "Inter-ictal Causal Graph Skeleton (Undirected): No skeleton generated or skeleton is empty.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "505b795a"
      },
      "source": [
        "## Consider Inherent Dataset Properties\n",
        "\n",
        "### Subtask:\n",
        "Discuss whether the inherent characteristics of the CHBMIT EEG dataset (e.g., high noise, non-stationarity, complex multivariate relationships) themselves make it challenging for constraint-based algorithms like PC to find clear causal structures. We will explore if other causal inference methods might be more suitable if the issue is fundamental to the data type.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85054120"
      },
      "source": [
        "## Consider Inherent Dataset Properties\n",
        "\n",
        "### Impact of CHBMIT EEG Dataset Characteristics on PC Algorithm\n",
        "\n",
        "The CHBMIT EEG dataset, like most neurophysiological recordings, possesses several inherent characteristics that can significantly challenge constraint-based causal discovery algorithms such as the PC algorithm:\n",
        "\n",
        "1.  **High Noise Levels**: EEG signals are notoriously noisy. They are susceptible to biological artifacts (e.g., eye blinks, muscle activity, heartbeats) and environmental interference (e.g., power line noise). While preprocessing aims to reduce noise, it's impossible to eliminate it entirely. High noise levels can obscure genuine causal relationships, leading to false negatives (missing true links) or false positives (identifying spurious links) in independence tests, making the PC algorithm less reliable.\n",
        "\n",
        "2.  **Non-stationarity**: Brain activity, especially during dynamic processes like seizures or changes in cognitive state, is inherently non-stationary. This means that the statistical properties of the EEG signals (mean, variance, spectral content, and crucially, their causal relationships) change over time. The standard PC algorithm assumes stationarity and i.i.d. (independent and identically distributed) observations, which is often violated in EEG data. Applying PC to non-stationary data can yield misleading causal structures that represent an average or transient state, rather than a stable underlying mechanism.\n",
        "\n",
        "3.  **Complex Multivariate Relationships**: EEG data involves many channels recording activity from different brain regions, reflecting a highly complex and interconnected system. Causal relationships in the brain are often non-linear, time-lagged, and involve feedback loops. The PC algorithm, while capable of detecting non-linear dependencies (when `hsic` is used), is primarily designed for acyclic graphs. Furthermore, its reliance on conditional independence tests can become computationally prohibitive and statistically unstable with a large number of variables, especially when high-order conditional independencies are required.\n",
        "\n",
        "4.  **Temporal Dependencies**: The PC algorithm, in its standard form, infers contemporaneous causal relationships. However, neural interactions are fundamentally dynamic and time-dependent. One brain region might influence another with a short delay. If the data has been aggregated into static 'snapshots' without preserving temporal order, these crucial time-lagged causal links cannot be discovered by standard PC.\n",
        "\n",
        "### Suitability of Other Causal Inference Methods for EEG Data\n",
        "\n",
        "Given the challenges posed by EEG data's inherent characteristics, several other causal inference methods might be more suitable, particularly those designed for time-series data:\n",
        "\n",
        "1.  **Granger Causality (GC)**: This is a popular method for time-series data, defining causality based on predictability: if past values of variable X help predict future values of variable Y better than past values of Y alone, then X Granger-causes Y. GC is well-suited for detecting time-lagged causal influences, which are prevalent in neural circuits. It can be applied in both time-domain (vector autoregressive models) and frequency-domain (spectral Granger causality) to identify directional flow of information.\n",
        "\n",
        "2.  **Dynamic Causal Modeling (DCM)**: A model-based approach where researchers specify a plausible network model of interacting brain regions and then use Bayesian inference to estimate the parameters of the model, including the strength and direction of causal connections, by fitting it to observed neurophysiological data. DCM explicitly accounts for non-stationarity (through model parameters) and provides a more biophysically informed interpretation of causal influences. It requires strong prior knowledge of the network structure but can infer hidden states and context-dependent changes.\n",
        "\n",
        "3.  **Transfer Entropy (TE)**: A non-parametric measure of directed information transfer between two time series. TE quantifies how much better the future state of one time series can be predicted by knowing the past states of another time series, beyond what can be predicted from its own past. It is model-free, can capture non-linear dependencies, and is robust to some forms of noise. TE is particularly useful for analyzing information flow in complex systems like the brain.\n",
        "\n",
        "4.  **LiNGAM (Linear Non-Gaussian Acyclic Model)**: This method extends independent component analysis (ICA) to causal discovery for linear, acyclic models where the noise terms are non-Gaussian. Unlike PC, LiNGAM can identify the full causal order (up to scaling and permutation) without relying on conditional independence tests or an independence oracle. While it assumes linearity and acyclicity, its ability to leverage non-Gaussianity can be powerful in scenarios where PC might struggle due to high-dimensional conditioning sets.\n",
        "\n",
        "5.  **Time-Series Extensions of PC**: While standard PC is not ideal, researchers have developed extensions that incorporate temporal information, such as `PCMCI` (PC algorithm for Moment-based Conditional Independence) or `Granger-PC`. These methods adapt the constraint-based framework to explicitly handle temporal dependencies and lagged effects, making them more appropriate for time-series data while retaining some of the advantages of the PC algorithm.\n",
        "\n",
        "In summary, while `StandardScaler` and duplicate removal are generally benign preprocessing steps, the fundamental nature of EEG data (noise, non-stationarity, temporal dynamics) inherently limits the efficacy of standard PC. For a more robust and biologically meaningful causal inference in EEG, methods explicitly designed for time-series analysis and capable of handling non-stationarity and non-linearity are often more appropriate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4df2d31"
      },
      "source": [
        "## Outline Custom Preprocessing Strategy (if needed)\n",
        "\n",
        "### Subtask:\n",
        "If custom preprocessing is deemed necessary, outline a strategy for downloading and preparing the raw CHBMIT dataset. This step will cover key preprocessing steps relevant for causal inference, such as artifact removal, bandpass filtering, and segmentation, ensuring that the data retains information important for discovering causal relationships.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f573f221"
      },
      "source": [
        "## Outline Custom Preprocessing Strategy for Raw CHBMIT Dataset\n",
        "\n",
        "Given that the current preprocessed `chbmit_preprocessed_data.csv` might have lost critical temporal and spectral information essential for comprehensive causal inference, a custom preprocessing strategy for the raw CHBMIT dataset is necessary. This strategy aims to preserve and highlight these dynamics, making the data suitable for more advanced time-series causal discovery methods.\n",
        "\n",
        "### 1. Data Acquisition: Downloading the Raw CHBMIT Dataset\n",
        "\n",
        "The CHBMIT Scalp EEG Database is publicly available on [PhysioNet](https://physionet.org/content/chbmit/1.0.0/). The dataset consists of continuous EEG recordings from pediatric subjects with intractable seizures. It is provided in EDF (European Data Format) files, which contain raw EEG signals along with metadata.\n",
        "\n",
        "**Steps:**\n",
        "1.  **Access PhysioNet:** Navigate to the CHBMIT Scalp EEG Database on PhysioNet.\n",
        "2.  **Download EDF Files:** Download the raw EDF files for the desired subjects. This often requires registration and agreement to the usage terms.\n",
        "3.  **Metadata:** Ensure to also download and parse associated metadata (e.g., `.txt` files) which contain information about seizure onset times, channel labels, and sampling frequencies.\n",
        "\n",
        "### 2. Key Preprocessing Steps for Causal Inference\n",
        "\n",
        "This section details preprocessing steps that focus on cleaning the raw EEG data while retaining the nuanced temporal and spectral information crucial for causal discovery.\n",
        "\n",
        "#### a. Initial Data Loading and Inspection\n",
        "\n",
        "*   **Load EDFs:** Use libraries like `mne-python` to load the `.edf` files. MNE provides robust tools for handling EEG/MEG data.\n",
        "*   **Channel Selection:** Select relevant EEG channels and drop any external channels (e.g., EKG, EOG) not intended for analysis, or use them for artifact detection.\n",
        "*   **Sampling Rate:** Note the original sampling frequency of the recordings, as this dictates the temporal resolution.\n",
        "\n",
        "#### b. Artifact Removal\n",
        "\n",
        "Artifacts (e.g., eye blinks, muscle activity, line noise) can introduce spurious correlations and obscure true neural dependencies. Effective artifact removal is paramount.\n",
        "\n",
        "*   **Line Noise Filtering:** Apply a notch filter (e.g., at 50 Hz or 60 Hz, depending on geographical location) to remove power line interference.\n",
        "*   **Ocular Artifacts (EOG):** Implement Independent Component Analysis (ICA) or regression-based methods to identify and remove components related to eye movements and blinks. MNE's ICA implementation is highly effective.\n",
        "*   **Muscle Artifacts (EMG):** While harder to remove completely without affecting neural signals, methods like ICA can help. Alternatively, segments with high EMG activity can be identified and excluded, or specific frequency ranges associated with muscle activity can be attenuated.\n",
        "*   **Bad Channels/Epochs:** Visually inspect data or use automated methods (e.g., based on amplitude thresholds, variance) to identify and interpolate or reject noisy channels/epochs.\n",
        "\n",
        "#### c. Bandpass Filtering\n",
        "\n",
        "Bandpass filtering helps isolate specific frequency bands and remove very slow drifts and very high-frequency noise, which are often non-physiological or not relevant for the causal questions.\n",
        "\n",
        "*   **Typical Range:** Apply a bandpass filter (e.g., 0.5 - 45 Hz or 1 - 70 Hz) to focus on the physiologically relevant EEG spectrum. This removes slow drifts (below 0.5 Hz) and high-frequency noise (above 45-70 Hz).\n",
        "*   **Preservation of Neural Frequencies:** Ensure that the filter cut-offs are chosen to preserve the major neural oscillations (delta, theta, alpha, beta, gamma) which are often implicated in brain dynamics and causal interactions. This is crucial as causal effects can be frequency-specific.\n",
        "\n",
        "#### d. Re-referencing\n",
        "\n",
        "EEG signals are recorded with respect to a reference electrode. Re-referencing can significantly impact the spatial distribution of signals and, consequently, observed causal links.\n",
        "\n",
        "*   **Common Average Reference (CAR):** Subtract the average activity across all electrodes from each electrode. This is a common method that can reduce noise common to all channels.\n",
        "*   **Reference Electrode Standardization Technique (REST):** A more sophisticated method that estimates a reference at infinity, which can provide a more accurate representation of brain activity.\n",
        "*   **Bipolar/Laplacian:** For specific analyses, creating bipolar montages or applying Laplacian (source) derivations can enhance spatial specificity and reduce volume conduction effects, which are critical for inferring direct causal influences between distinct brain regions.\n",
        "\n",
        "#### e. Segmentation (Epoching)\n",
        "\n",
        "Segmenting continuous EEG data into meaningful epochs is essential for analyzing specific states or events.\n",
        "\n",
        "*   **Event-Related Segmentation:** Epoch the data around events of interest, such as seizure onset markers (from metadata) or specific cognitive tasks.\n",
        "*   **State-Based Segmentation:** For inter-ictal and pre-ictal analysis, segment continuous data into fixed-duration, non-overlapping windows. Crucially, *maintain the temporal order of segments within each state*. For instance, a pre-ictal state could be defined as a continuous block of X minutes leading up to a seizure. This preserves the temporal sequence within the state, which is vital for time-series causal inference.\n",
        "*   **Temporal Continuity:** Unlike the current approach which treats each row as an i.i.d. sample, ensure that when segments are created, their temporal relationship (e.g., segment N precedes segment N+1) is maintained or at least considered. This allows for the investigation of time-lagged causal effects.\n",
        "\n",
        "#### f. Resampling (Downsampling)\n",
        "\n",
        "Raw EEG data often has high sampling rates (e.g., 256 Hz, 512 Hz). Downsampling can reduce computational load but must be done carefully.\n",
        "\n",
        "*   **Purpose:** Reduce the sampling rate to a more manageable level (e.g., 100-200 Hz) while preserving relevant frequency content. Downsampling too aggressively can lead to aliasing and loss of high-frequency information.\n",
        "*   **Anti-aliasing Filter:** Always apply an anti-aliasing low-pass filter before downsampling to prevent spectral folding.\n",
        "*   **Impact on Temporal Resolution:** Acknowledge the trade-off: downsampling reduces the temporal resolution, which might affect the detection of very fast, short-lagged causal interactions. The chosen sampling rate should still be high enough to capture the fastest relevant neural dynamics.\n",
        "\n",
        "### 3. Retaining Crucial Information for Causal Discovery\n",
        "\n",
        "This custom preprocessing strategy is designed to mitigate the potential loss of temporal and spectral information identified in the existing preprocessed data:\n",
        "\n",
        "*   **Temporal Information:** By explicitly segmenting continuous data with an awareness of temporal order and avoiding treating each time point as an i.i.d. snapshot, we retain the sequential nature of EEG. This allows for the detection of time-lagged causal effects (e.g., Granger causality).\n",
        "*   **Spectral Information:** Careful bandpass filtering and avoiding aggregation over frequency bands ensure that the power and phase relationships within different oscillations are preserved. This enables causal discovery methods that can operate on frequency-specific measures or investigate cross-frequency coupling.\n",
        "*   **Reduced Volume Conduction:** Re-referencing techniques like REST or Laplacian derivations help minimize the effects of volume conduction, leading to more accurate estimates of direct neural interactions rather than spurious correlations due to shared signal spread.\n",
        "\n",
        "### 4. Preparing for Advanced Time-Series Causal Inference\n",
        "\n",
        "By implementing this strategy, the preprocessed data becomes suitable for a range of advanced causal inference methods that explicitly model temporal dynamics:\n",
        "\n",
        "*   **Granger Causality:** Can be applied to the segmented, clean time series data to infer directional causal influences over time.\n",
        "*   **Dynamic Causal Modeling (DCM):** A more model-driven approach that requires biologically plausible models of neural interactions, typically applied to source-localized data, which can be derived from the preprocessed EEG.\n",
        "*   **Time-Series Extensions of PC:** Algorithms like PC-LST (PC-Lagged with Sparse Time-series) or other variants that incorporate time lags into conditional independence tests can be applied to infer dynamic causal graphs.\n",
        "*   **Multivariate Autoregressive (MVAR) Models:** These models can capture the dynamic interactions between multiple brain regions over time, providing insights into causal flow.\n",
        "\n",
        "This comprehensive preprocessing framework, though more intensive, ensures that the resulting data maximizes the potential for uncovering genuine, nuanced causal relationships within the CHBMIT EEG dataset, addressing the limitations of applying static causal inference methods to overly aggregated data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c9d81dba"
      },
      "source": [
        "## Outline Custom Preprocessing Strategy for Raw CHBMIT Dataset\n",
        "\n",
        "Given that the current preprocessed `chbmit_preprocessed_data.csv` might have lost critical temporal and spectral information essential for comprehensive causal inference, a custom preprocessing strategy for the raw CHBMIT dataset is necessary. This strategy aims to preserve and highlight these dynamics, making the data suitable for more advanced time-series causal discovery methods.\n",
        "\n",
        "### 1. Data Acquisition: Downloading the Raw CHBMIT Dataset\n",
        "\n",
        "The CHBMIT Scalp EEG Database is publicly available on [PhysioNet](https://physionet.org/content/chbmit/1.0.0/). The dataset consists of continuous EEG recordings from pediatric subjects with intractable seizures. It is provided in EDF (European Data Format) files, which contain raw EEG signals along with metadata.\n",
        "\n",
        "**Steps:**\n",
        "1.  **Access PhysioNet:** Navigate to the CHBMIT Scalp EEG Database on PhysioNet.\n",
        "2.  **Download EDF Files:** Download the raw EDF files for the desired subjects. This often requires registration and agreement to the usage terms.\n",
        "3.  **Metadata:** Ensure to also download and parse associated metadata (e.g., `.txt` files) which contain information about seizure onset times, channel labels, and sampling frequencies.\n",
        "\n",
        "### 2. Key Preprocessing Steps for Causal Inference\n",
        "\n",
        "This section details preprocessing steps that focus on cleaning the raw EEG data while retaining the nuanced temporal and spectral information crucial for causal discovery.\n",
        "\n",
        "#### a. Initial Data Loading and Inspection\n",
        "\n",
        "*   **Load EDFs:** Use libraries like `mne-python` to load the `.edf` files. MNE provides robust tools for handling EEG/MEG data.\n",
        "*   **Channel Selection:** Select relevant EEG channels and drop any external channels (e.g., EKG, EOG) not intended for analysis, or use them for artifact detection.\n",
        "*   **Sampling Rate:** Note the original sampling frequency of the recordings, as this dictates the temporal resolution.\n",
        "\n",
        "#### b. Artifact Removal\n",
        "\n",
        "Artifacts (e.g., eye blinks, muscle activity, line noise) can introduce spurious correlations and obscure true neural dependencies. Effective artifact removal is paramount.\n",
        "\n",
        "*   **Line Noise Filtering:** Apply a notch filter (e.g., at 50 Hz or 60 Hz, depending on geographical location) to remove power line interference.\n",
        "*   **Ocular Artifacts (EOG):** Implement Independent Component Analysis (ICA) or regression-based methods to identify and remove components related to eye movements and blinks. MNE's ICA implementation is highly effective.\n",
        "*   **Muscle Artifacts (EMG):** While harder to remove completely without affecting neural signals, methods like ICA can help. Alternatively, segments with high EMG activity can be identified and excluded, or specific frequency ranges associated with muscle activity can be attenuated.\n",
        "*   **Bad Channels/Epochs:** Visually inspect data or use automated methods (e.g., based on amplitude thresholds, variance) to identify and interpolate or reject noisy channels/epochs.\n",
        "\n",
        "#### c. Bandpass Filtering\n",
        "\n",
        "Bandpass filtering helps isolate specific frequency bands and remove very slow drifts and very high-frequency noise, which are often non-physiological or not relevant for the causal questions.\n",
        "\n",
        "*   **Typical Range:** Apply a bandpass filter (e.g., 0.5 - 45 Hz or 1 - 70 Hz) to focus on the physiologically relevant EEG spectrum. This removes slow drifts (below 0.5 Hz) and high-frequency noise (above 45-70 Hz).\n",
        "*   **Preservation of Neural Frequencies:** Ensure that the filter cut-offs are chosen to preserve the major neural oscillations (delta, theta, alpha, beta, gamma) which are often implicated in brain dynamics and causal interactions. This is crucial as causal effects can be frequency-specific.\n",
        "\n",
        "#### d. Re-referencing\n",
        "\n",
        "EEG signals are recorded with respect to a reference electrode. Re-referencing can significantly impact the spatial distribution of signals and, consequently, observed causal links.\n",
        "\n",
        "*   **Common Average Reference (CAR):** Subtract the average activity across all electrodes from each electrode. This is a common method that can reduce noise common to all channels.\n",
        "*   **Reference Electrode Standardization Technique (REST):** A more sophisticated method that estimates a reference at infinity, which can provide a more accurate representation of brain activity.\n",
        "*   **Bipolar/Laplacian:** For specific analyses, creating bipolar montages or applying Laplacian (source) derivations can enhance spatial specificity and reduce volume conduction effects, which are critical for inferring direct causal influences between distinct brain regions.\n",
        "\n",
        "#### e. Segmentation (Epoching)\n",
        "\n",
        "Segmenting continuous EEG data into meaningful epochs is essential for analyzing specific states or events.\n",
        "\n",
        "*   **Event-Related Segmentation:** Epoch the data around events of interest, such as seizure onset markers (from metadata) or specific cognitive tasks.\n",
        "*   **State-Based Segmentation:** For inter-ictal and pre-ictal analysis, segment continuous data into fixed-duration, non-overlapping windows. Crucially, *maintain the temporal order of segments within each state*. For instance, a pre-ictal state could be defined as a continuous block of X minutes leading up to a seizure. This preserves the temporal sequence within the state, which is vital for time-series causal inference.\n",
        "*   **Temporal Continuity:** Unlike the current approach which treats each row as an i.i.d. sample, ensure that when segments are created, their temporal relationship (e.g., segment N precedes segment N+1) is maintained or at least considered. This allows for the investigation of time-lagged causal effects.\n",
        "\n",
        "#### f. Resampling (Downsampling)\n",
        "\n",
        "Raw EEG data often has high sampling rates (e.g., 256 Hz, 512 Hz). Downsampling can reduce computational load but must be done carefully.\n",
        "\n",
        "*   **Purpose:** Reduce the sampling rate to a more manageable level (e.g., 100-200 Hz) while preserving relevant frequency content. Downsampling too aggressively can lead to aliasing and loss of high-frequency information.\n",
        "*   **Anti-aliasing Filter:** Always apply an anti-aliasing low-pass filter before downsampling to prevent spectral folding.\n",
        "*   **Impact on Temporal Resolution:** Acknowledge the trade-off: downsampling reduces the temporal resolution, which might affect the detection of very fast, short-lagged causal interactions. The chosen sampling rate should still be high enough to capture the fastest relevant neural dynamics.\n",
        "\n",
        "### 3. Retaining Crucial Information for Causal Discovery\n",
        "\n",
        "This custom preprocessing strategy is designed to mitigate the potential loss of temporal and spectral information identified in the existing preprocessed data:\n",
        "\n",
        "*   **Temporal Information:** By explicitly segmenting continuous data with an awareness of temporal order and avoiding treating each time point as an i.i.d. snapshot, we retain the sequential nature of EEG. This allows for the detection of time-lagged causal effects (e.g., Granger causality).\n",
        "*   **Spectral Information:** Careful bandpass filtering and avoiding aggregation over frequency bands ensure that the power and phase relationships within different oscillations are preserved. This enables causal discovery methods that can operate on frequency-specific measures or investigate cross-frequency coupling.\n",
        "*   **Reduced Volume Conduction:** Re-referencing techniques like REST or Laplacian derivations help minimize the effects of volume conduction, leading to more accurate estimates of direct neural interactions rather than spurious correlations due to shared signal spread.\n",
        "\n",
        "### 4. Preparing for Advanced Time-Series Causal Inference\n",
        "\n",
        "By implementing this strategy, the preprocessed data becomes suitable for a range of advanced causal inference methods that explicitly model temporal dynamics:\n",
        "\n",
        "*   **Granger Causality:** Can be applied to the segmented, clean time series data to infer directional causal influences over time.\n",
        "*   **Dynamic Causal Modeling (DCM):** A more model-driven approach that requires biologically plausible models of neural interactions, typically applied to source-localized data, which can be derived from the preprocessed EEG.\n",
        "*   **Time-Series Extensions of PC:** Algorithms like PC-LST (PC-Lagged with Sparse Time-series) or other variants that incorporate time lags into conditional independence tests can be applied to infer dynamic causal graphs.\n",
        "*   **Multivariate Autoregressive (MVAR) Models:** These models can capture the dynamic interactions between multiple brain regions over time, providing insights into causal flow.\n",
        "\n",
        "This comprehensive preprocessing framework, though more intensive, ensures that the resulting data maximizes the potential for uncovering genuine, nuanced causal relationships within the CHBMIT EEG dataset, addressing the limitations of applying static causal inference methods to overly aggregated data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3be67787"
      },
      "source": [
        "## Address Space and Memory Constraints\n",
        "\n",
        "### Subtask:\n",
        "Provide practical strategies for preprocessing a large dataset like CHBMIT without running out of space or memory. This includes techniques like processing data in chunks, selective downsampling, using memory-efficient data structures, and storing intermediate results efficiently. We will also discuss the implications of these choices on causal inference.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef5e649c"
      },
      "source": [
        "## Address Space and Memory Constraints\n",
        "\n",
        "### Practical Strategies for Handling Large EEG Datasets\n",
        "\n",
        "Working with large EEG datasets like CHBMIT often presents significant memory and space challenges during preprocessing. Efficient strategies are crucial to avoid running out of RAM or disk space while preparing the data for causal inference. Below are several practical techniques and their implications.\n",
        "\n",
        "#### 1. Processing Data in Manageable Chunks\n",
        "\n",
        "Instead of loading the entire dataset into memory, processing it in smaller, manageable chunks is a fundamental strategy. This can be implemented in several ways:\n",
        "\n",
        "*   **Subject-by-Subject**: If the dataset consists of recordings from multiple subjects, process one subject's data at a time. Load all files for a single subject, preprocess them, extract features, and save the results before moving to the next subject.\n",
        "*   **File-by-File**: For datasets where each recording session is stored in a separate file (e.g., individual EEG recordings), process each file sequentially. This is often applicable when a single subject has multiple recording sessions.\n",
        "*   **Time-Window-by-Time-Window**: Within a single long recording, data can be processed in fixed-duration time windows (e.g., 5-second segments). Features are extracted from each window, and the windows are processed iteratively.\n",
        "\n",
        "**Implications for Causal Inference**: Chunking is generally benign if the causal inference is performed *within* each chunk and then aggregated or if the chunks are representative samples. However, if causal links span across chunk boundaries (e.g., a causal effect originating in one time window and manifesting in the next), simple chunking might break these dependencies. When aggregating results, care must be taken to ensure the statistical methods are appropriate for combined inferences from multiple independent analyses.\n",
        "\n",
        "#### 2. Selective Downsampling\n",
        "\n",
        "EEG data is often acquired at high sampling rates (e.g., 250 Hz, 500 Hz, or more). Downsampling can drastically reduce memory and storage requirements.\n",
        "\n",
        "*   **Method**: Reduce the sampling frequency of the EEG signals. For example, downsampling from 500 Hz to 100 Hz reduces the data points by a factor of 5.\n",
        "*   **Trade-offs with Temporal Resolution**: The main trade-off is the loss of temporal resolution. Downsampling limits the highest frequency components that can be analyzed (Nyquist frequency). If very fast neurological events or short-lagged causal interactions (e.g., within milliseconds) are crucial, aggressive downsampling can obscure these. However, for slower cortical dynamics or analyses focusing on broader frequency bands, downsampling can be acceptable or even beneficial by removing high-frequency noise.\n",
        "\n",
        "**Implications for Causal Inference**: Downsampling directly impacts the ability to detect rapid causal effects. Causal links with short time lags might become undetectable or appear as instantaneous effects if the time resolution is insufficient. It's crucial to consider the expected temporal scale of the causal phenomena being investigated when deciding on a downsampling factor.\n",
        "\n",
        "#### 3. Using Memory-Efficient Data Structures\n",
        "\n",
        "Choosing the right data structures can significantly reduce memory footprint.\n",
        "\n",
        "*   **NumPy Arrays**: Python lists are memory-inefficient for numerical data. Using NumPy arrays is essential as they store data in a contiguous block of memory, offering lower memory usage and faster operations.\n",
        "*   **`h5py` for Out-of-Core Processing**: For datasets that are too large to fit in memory even with NumPy, `h5py` allows interaction with HDF5 files on disk as if they were NumPy arrays. This enables out-of-core computations where only a small portion of data is loaded into RAM at any given time.\n",
        "*   **Sparse Matrices**: If the extracted features are sparse (contain many zero values), using sparse matrix formats (e.g., from `scipy.sparse`) can save considerable memory.\n",
        "\n",
        "**Implications for Causal Inference**: These are primarily technical optimizations that enable processing of larger datasets. They do not directly alter the causal inference logic but ensure that the PC algorithm (or other methods) can actually run on the data without memory crashes. Efficient data structures contribute to faster processing, which can be critical for iterative causal discovery workflows.\n",
        "\n",
        "#### 4. Efficient Storage of Intermediate Results\n",
        "\n",
        "After each major preprocessing step (e.g., artifact removal, feature extraction, state separation), saving the intermediate results to disk in an efficient format is good practice.\n",
        "\n",
        "*   **Formats**: Consider formats like:\n",
        "    *   `.fif` (MEG/EEG data format, often used with MNE-Python for raw/processed signals).\n",
        "    *   `.hdf5` (Hierarchical Data Format 5): Excellent for storing large numerical datasets with metadata, supporting compression and fast access to subsets of data.\n",
        "    *   `.parquet`: Columnar storage format, highly efficient for tabular data, especially with large numbers of rows, and supports schema evolution and compression.\n",
        "    *   `.npy` or `.npz`: For saving raw NumPy arrays efficiently.\n",
        "*   **Benefits**: Prevents data loss, allows resuming processing from an intermediate step, reduces re-computation time, and facilitates sharing of processed data.\n",
        "\n",
        "**Implications for Causal Inference**: Storing intermediate results enhances reproducibility and makes the causal inference pipeline more robust. If a causal discovery step fails or needs parameter tuning, having preprocessed stages saved means one doesn't have to restart from raw data. It also allows for easier experimentation with different causal inference algorithms or parameters on the same preprocessed data.\n",
        "\n",
        "By carefully applying these strategies, researchers can effectively manage the memory and space requirements of large EEG datasets, enabling complex analyses like causal inference that would otherwise be computationally prohibitive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91730633"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the findings regarding the current dataset and provide a conclusive recommendation on whether to proceed with custom preprocessing and how to manage the process effectively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26530d13"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "**Should we proceed with custom preprocessing and how should we manage the process effectively?**\n",
        "Yes, custom preprocessing is highly recommended and necessary. The current preprocessing, while standard, likely stripped critical temporal and spectral information from the CHBMIT EEG dataset, leading to an empty causal graph when applying the PC algorithm. To manage the process effectively, a comprehensive strategy involving careful raw data acquisition, detailed artifact removal, bandpass filtering, re-referencing, segmentation that preserves temporal continuity, and selective downsampling will be crucial. Memory and space constraints can be managed through data chunking, memory-efficient data structures, and efficient storage of intermediate results.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "*   **Empty Causal Graph**: The PC algorithm, when applied to the inter-ictal state data using the existing preprocessing and alpha level, resulted in an **empty directed causal graph and an empty skeleton**. This indicates that the algorithm found **no statistically significant causal links** under the given conditions, rather than an issue with graph conversion.\n",
        "*   **Impact of Existing Preprocessing**:\n",
        "    *   **StandardScaler** and **duplicate column removal** were deemed benign, preserving linear relationships and simplifying the data without information loss for conditional independence tests using `hsic`.\n",
        "    *   However, the initial creation of the `chbmit_preprocessed_data.csv` likely led to a **significant loss of temporal and spectral resolution**, which is critical for EEG causal inference. The data appears to be treated as i.i.d. samples, violating the inherent temporal dependencies of EEG.\n",
        "*   **Inherent Challenges of EEG Data for PC Algorithm**: EEG datasets present fundamental challenges for constraint-based algorithms like the PC algorithm due to:\n",
        "    *   **High Noise Levels**: Obscuring genuine causal relationships.\n",
        "    *   **Non-stationarity**: Causal relationships in EEG change over time, violating PC's stationarity assumption.\n",
        "    *   **Complex Multivariate Relationships**: Non-linear, time-lagged, and feedback loop-driven interactions are not fully captured by standard PC.\n",
        "    *   **Temporal Dependencies**: Standard PC primarily infers contemporaneous relationships, missing crucial time-lagged effects.\n",
        "*   **Trade-offs of Preprocessed vs. Raw Data**: While preprocessed data offers benefits like reduced noise, dimensionality reduction, and computational efficiency, it comes at the cost of losing vital temporal and spectral resolution, obscuring non-linearities, and violating i.i.d. assumptions for time-series data. Raw data preserves full information but is high-dimensional and complex.\n",
        "*   **Need for Custom Preprocessing**: To address the limitations, a custom preprocessing strategy for raw CHBMIT data is essential. This includes artifact removal (notch filtering, ICA for ocular artifacts), bandpass filtering for relevant frequencies, re-referencing (CAR, REST, Laplacian) to reduce volume conduction, segmentation that *maintains temporal order*, and careful resampling.\n",
        "*   **Memory and Space Management**: For large datasets, practical strategies include processing data in manageable chunks (subject-by-subject, file-by-file, time-window-by-time-window), selective downsampling with anti-aliasing, using memory-efficient data structures (NumPy, `h5py`, sparse matrices), and efficiently storing intermediate results (`.fif`, `.hdf5`, `.parquet`).\n",
        "\n",
        "### Insights or Next Steps\n",
        "*   **Implement Custom Preprocessing**: Proceed with the outlined custom preprocessing strategy for the raw CHBMIT dataset, focusing on preserving temporal and spectral information and ensuring appropriate handling of time series characteristics. This is a critical first step to enable meaningful causal inference in EEG.\n",
        "*   **Explore Alternative Causal Inference Methods**: Given the limitations of the standard PC algorithm for EEG data, investigate and apply time-series-specific causal inference methods such as Granger Causality, Transfer Entropy, Dynamic Causal Modeling (DCM), or time-series extensions of PC (e.g., `PCMCI`) once the data is appropriately preprocessed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdf4503e"
      },
      "source": [
        "# Task\n",
        "Install `mne` library for EEG data loading and preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4839b37a"
      },
      "source": [
        "## Install MNE-Python\n",
        "\n",
        "### Subtask:\n",
        "Install the `mne` library, which is essential for loading and preprocessing raw EEG data (EDF files). This library provides robust tools for neurophysiological signal processing. This step does not significantly impact memory or space.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bc3211d"
      },
      "source": [
        "**Reasoning**:\n",
        "Install the mne library using pip, which is essential for loading and preprocessing raw EEG data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "439dfb9e",
        "outputId": "2dd03eca-d00d-441a-f15f-b12409118924"
      },
      "source": [
        "pip install mne"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mne in /usr/local/lib/python3.12/dist-packages (1.11.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from mne) (3.1.6)\n",
            "Requirement already satisfied: lazy-loader>=0.3 in /usr/local/lib/python3.12/dist-packages (from mne) (0.4)\n",
            "Requirement already satisfied: matplotlib>=3.8 in /usr/local/lib/python3.12/dist-packages (from mne) (3.10.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26 in /usr/local/lib/python3.12/dist-packages (from mne) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mne) (25.0)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.12/dist-packages (from mne) (1.8.2)\n",
            "Requirement already satisfied: scipy>=1.11 in /usr/local/lib/python3.12/dist-packages (from mne) (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from mne) (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.8->mne) (2.9.0.post0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.5->mne) (2.32.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->mne) (3.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.8->mne) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f37d72df"
      },
      "source": [
        "## Acquire Raw CHBMIT Data (Chunk-wise)\n",
        "\n",
        "### Subtask:\n",
        "Manually download portions of the raw CHBMIT dataset from PhysioNet. To manage space, download data in manageable chunks (e.g., subject-by-subject or a few files at a time) rather than the entire dataset simultaneously. Store these raw files in a designated local directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80146ce4"
      },
      "source": [
        "## Acquire Raw CHBMIT Data (Chunk-wise)\n",
        "\n",
        "### Subtask:\n",
        "Manually download portions of the raw CHBMIT dataset from PhysioNet. To manage space, download data in manageable chunks (e.g., subject-by-subject or a few files at a time) rather than the entire dataset simultaneously. Store these raw files in a designated local directory.\n",
        "\n",
        "#### Instructions\n",
        "1. Access the CHBMIT Scalp EEG Database on PhysioNet (https://physionet.org/content/chbmit/1.0.0/).\n",
        "2. Download the raw EDF files for a few selected subjects or a manageable subset of the data. You may need to register and agree to their usage terms.\n",
        "3. Create a local directory (e.g., `/content/data/raw/chbmit/`) to store these downloaded raw EDF files.\n",
        "4. Store the downloaded EDF files, along with any associated metadata (e.g., `.txt` files containing seizure onset times), into this newly created directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68631210"
      },
      "source": [
        "## Acquire Raw CHBMIT Data (Chunk-wise)\n",
        "\n",
        "### Subtask:\n",
        "Manually download portions of the raw CHBMIT dataset from PhysioNet. To manage space, download data in manageable chunks (e.g., subject-by-subject or a few files at a time) rather than the entire dataset simultaneously. Store these raw files in a designated local directory.\n",
        "\n",
        "#### Instructions\n",
        "1. Access the CHBMIT Scalp EEG Database on PhysioNet (https://physionet.org/content/chbmit/1.0.0/).\n",
        "2. Download the raw EDF files for a few selected subjects or a manageable subset of the data. You may need to register and agree to their usage terms.\n",
        "3. Create a local directory (e.g., `/content/data/raw/chbmit/`) to store these downloaded raw EDF files.\n",
        "4. Store the downloaded EDF files, along with any associated metadata (e.g., `.txt` files containing seizure onset times), into this newly created directory."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77e1b05b"
      },
      "source": [
        "## Acquire Raw CHBMIT Data (Chunk-wise)\n",
        "\n",
        "### Subtask:\n",
        "Manually download portions of the raw CHBMIT dataset from PhysioNet. To manage space, download data in manageable chunks (e.g., subject-by-subject or a few files at a time) rather than the entire dataset simultaneously. Store these raw files in a designated local directory.\n",
        "\n",
        "#### Instructions\n",
        "1. Access the CHBMIT Scalp EEG Database on PhysioNet (https://physionet.org/content/chbmit/1.0.0/).\n",
        "2. Download the raw EDF files for a few selected subjects or a manageable subset of the data. You may need to register and agree to their usage terms.\n",
        "3. Create a local directory (e.g., `/content/data/raw/chbmit/`) to store these downloaded raw EDF files.\n",
        "4. Store the downloaded EDF files, along with any associated metadata (e.g., `.txt` files containing seizure onset times), into this newly created directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8c89189"
      },
      "source": [
        "## Acquire Raw CHBMIT Data (Chunk-wise)\n",
        "\n",
        "### Subtask:\n",
        "Manually download portions of the raw CHBMIT dataset from PhysioNet. To manage space, download data in manageable chunks (e.g., subject-by-subject or a few files at a time) rather than the entire dataset simultaneously. Store these raw files in a designated local directory.\n",
        "\n",
        "#### Instructions\n",
        "1. Access the CHBMIT Scalp EEG Database on PhysioNet (https://physionet.org/content/chbmit/1.0.0/).\n",
        "2. Download the raw EDF files for a few selected subjects or a manageable subset of the data. You may need to register and agree to their usage terms.\n",
        "3. Create a local directory (e.g., `/content/data/raw/chbmit/`) to store these downloaded raw EDF files.\n",
        "4. Store the downloaded EDF files, along with any associated metadata (e.g., `.txt` files containing seizure onset times), into this newly created directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6886c549"
      },
      "source": [
        "## Acquire Raw CHBMIT Data (Chunk-wise)\n",
        "\n",
        "### Subtask:\n",
        "Manually download portions of the raw CHBMIT dataset from PhysioNet. To manage space, download data in manageable chunks (e.g., subject-by-subject or a few files at a time) rather than the entire dataset simultaneously. Store these raw files in a designated local directory.\n",
        "\n",
        "#### Instructions\n",
        "1. Access the CHBMIT Scalp EEG Database on PhysioNet (https://physionet.org/content/chbmit/1.0.0/).\n",
        "2. Download the raw EDF files for a few selected subjects or a manageable subset of the data. You may need to register and agree to their usage terms.\n",
        "3. Create a local directory (e.g., `/content/data/raw/chbmit/`) to store these downloaded raw EDF files.\n",
        "4. Store the downloaded EDF files, along with any associated metadata (e.g., `.txt` files containing seizure onset times), into this newly created directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1db8ff33"
      },
      "source": [
        "## Acquire Raw CHBMIT Data (Chunk-wise)\n",
        "\n",
        "### Subtask:\n",
        "Manually download portions of the raw CHBMIT dataset from PhysioNet. To manage space, download data in manageable chunks (e.g., subject-by-subject or a few files at a time) rather than the entire dataset simultaneously. Store these raw files in a designated local directory.\n",
        "\n",
        "#### Instructions\n",
        "1. Access the CHBMIT Scalp EEG Database on PhysioNet (https://physionet.org/content/chbmit/1.0.0/).\n",
        "2. Download the raw EDF files for a few selected subjects or a manageable subset of the data. You may need to register and agree to their usage terms.\n",
        "3. Create a local directory (e.g., `/content/data/raw/chbmit/`) to store these downloaded raw EDF files.\n",
        "4. Store the downloaded EDF files, along with any associated metadata (e.g., `.txt` files containing seizure onset times), into this newly created directory.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f66feda6"
      },
      "source": [
        "## Acquire Raw CHBMIT Data (Chunk-wise)\n",
        "\n",
        "### Subtask:\n",
        "Manually download portions of the raw CHBMIT dataset from PhysioNet. To manage space, download data in manageable chunks (e.g., subject-by-subject or a few files at a time) rather than the entire dataset simultaneously. Store these raw files in a designated local directory.\n",
        "\n",
        "#### Instructions\n",
        "1. Access the CHBMIT Scalp EEG Database on PhysioNet (https://physionet.org/content/chbmit/1.0.0/).\n",
        "2. Download the raw EDF files for a few selected subjects or a manageable subset of the data. You may need to register and agree to their usage terms.\n",
        "3. Create a local directory (e.g., `/content/data/raw/chbmit/`) to store these downloaded raw EDF files.\n",
        "4. Store the downloaded EDF files, along with any associated metadata (e.g., `.txt` files containing seizure onset times), into this newly created directory.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38172bf1"
      },
      "source": [
        "## Acquire Raw CHBMIT Data (Chunk-wise)\n",
        "\n",
        "### Subtask:\n",
        "Manually download portions of the raw CHBMIT dataset from PhysioNet. To manage space, download data in manageable chunks (e.g., subject-by-subject or a few files at a time) rather than the entire dataset simultaneously. Store these raw files in a designated local directory.\n",
        "\n",
        "#### Instructions\n",
        "1. Access the CHBMIT Scalp EEG Database on PhysioNet (https://physionet.org/content/chbmit/1.0.0/).\n",
        "2. Download the raw EDF files for a few selected subjects or a manageable subset of the data. You may need to register and agree to their usage terms.\n",
        "3. Create a local directory (e.g., `/content/data/raw/chbmit/`) to store these downloaded raw EDF files.\n",
        "4. Store the downloaded EDF files, along with any associated metadata (e.g., `.txt` files containing seizure onset times), into this newly created directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "111121af",
        "outputId": "8d79ad91-0a0b-4a8a-d142-4695ede2b3e4"
      },
      "source": [
        "import mne\n",
        "import os\n",
        "\n",
        "print(\"MNE-Python and os libraries imported successfully.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNE-Python and os libraries imported successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6f72e3a",
        "outputId": "a963ef8a-1fa5-43bb-d10f-42fb6359e913"
      },
      "source": [
        "import mne\n",
        "import os\n",
        "\n",
        "mne.set_log_level('WARNING') # Set log level to WARNING to reduce verbose output\n",
        "\n",
        "raw_data_dir = '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/CHB.01_01.edf'\n",
        "os.makedirs(raw_data_dir, exist_ok=True)\n",
        "\n",
        "# --- USER ACTION REQUIRED ---\n",
        "# Please manually download EDF files from PhysioNet and place them in the directory specified above.\n",
        "# Example: /content/data/raw/chbmit/chb01_01.edf\n",
        "# --------------------------\n",
        "\n",
        "# List all EDF files in the directory\n",
        "edf_files = [os.path.join(raw_data_dir, f) for f in os.listdir(raw_data_dir) if f.endswith('.edf')]\n",
        "\n",
        "if not edf_files:\n",
        "    print(f\"No EDF files found in {raw_data_dir}. Please download and place the raw CHBMIT EDF files there.\")\n",
        "else:\n",
        "    print(f\"Found {len(edf_files)} EDF files in {raw_data_dir}.\")\n",
        "    print(f\"Total {len(edf_files)} EDF files loaded for processing.\")\n",
        "    print(\"Example files:\", edf_files[:3]) # Print first 3 files if many\n",
        "\n",
        "# List to store preprocessed MNE Raw objects (or extracted data)\n",
        "preprocessed_raw_objects = []\n",
        "\n",
        "# Define preprocessing parameters\n",
        "low_freq = 0.5\n",
        "high_freq = 45\n",
        "new_sfreq = 100 # Hz\n",
        "\n",
        "if edf_files:\n",
        "    for i, edf_file in enumerate(edf_files):\n",
        "        print(f\"\\nProcessing file {i+1}/{len(edf_files)}: {os.path.basename(edf_file)}\")\n",
        "        try:\n",
        "            # 5a. Load the EDF file into an MNE Raw object\n",
        "            raw = mne.io.read_raw_edf(edf_file, preload=True)\n",
        "            # Ensure a descriptive name is set for saving later\n",
        "            raw.info['description'] = os.path.basename(edf_file).replace('.edf', '')\n",
        "            print(f\"  Original sampling frequency: {raw.info['sfreq']} Hz\")\n",
        "            print(f\"  Number of channels: {len(raw.ch_names)}\")\n",
        "            print(f\"  Duration: {raw.times[-1] / 60:.2f} minutes\")\n",
        "\n",
        "            # Apply common average reference to EEG channels only if they exist\n",
        "            eeg_channels = mne.pick_types(raw.info, eeg=True, exclude='bads')\n",
        "            if len(eeg_channels) > 0:\n",
        "                raw.set_eeg_reference(ref_channels='average')\n",
        "                print(\"  Applied Common Average Reference.\")\n",
        "            else:\n",
        "                print(\"  No EEG channels found for re-referencing.\")\n",
        "\n",
        "            # 5b. Apply a bandpass filter\n",
        "            raw.filter(l_freq=low_freq, h_freq=high_freq, picks='eeg')\n",
        "            print(f\"  Applied bandpass filter ({low_freq}-{high_freq} Hz).\")\n",
        "\n",
        "            # 5c. Downsample the Raw object\n",
        "            raw.resample(sfreq=new_sfreq)\n",
        "            print(f\"  Downsampled to {raw.info['sfreq']} Hz.\")\n",
        "\n",
        "            # 5d. Store the preprocessed Raw object (or its data)\n",
        "            preprocessed_raw_objects.append(raw) # Store the MNE Raw object\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error processing {os.path.basename(edf_file)}: {e}\")\n",
        "\n",
        "    print(f\"\\nFinished preprocessing {len(preprocessed_raw_objects)} files.\")\n",
        "else:\n",
        "    print(\"Skipping preprocessing as no EDF files were found.\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6 EDF files in /content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/CHB.01_01.edf.\n",
            "Total 6 EDF files loaded for processing.\n",
            "Example files: ['/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/CHB.01_01.edf/chb01_12.edf', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/CHB.01_01.edf/chb01_11.edf', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/CHB.01_01.edf/chb01_13.edf']\n",
            "\n",
            "Processing file 1/6: chb01_12.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2891246402.py:37: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(edf_file, preload=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original sampling frequency: 256.0 Hz\n",
            "  Number of channels: 23\n",
            "  Duration: 60.00 minutes\n",
            "  Applied Common Average Reference.\n",
            "  Applied bandpass filter (0.5-45 Hz).\n",
            "  Downsampled to 100.0 Hz.\n",
            "\n",
            "Processing file 2/6: chb01_11.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2891246402.py:37: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(edf_file, preload=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original sampling frequency: 256.0 Hz\n",
            "  Number of channels: 23\n",
            "  Duration: 60.00 minutes\n",
            "  Applied Common Average Reference.\n",
            "  Applied bandpass filter (0.5-45 Hz).\n",
            "  Downsampled to 100.0 Hz.\n",
            "\n",
            "Processing file 3/6: chb01_13.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2891246402.py:37: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(edf_file, preload=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original sampling frequency: 256.0 Hz\n",
            "  Number of channels: 23\n",
            "  Duration: 60.00 minutes\n",
            "  Applied Common Average Reference.\n",
            "  Applied bandpass filter (0.5-45 Hz).\n",
            "  Downsampled to 100.0 Hz.\n",
            "\n",
            "Processing file 4/6: chb01_14.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2891246402.py:37: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(edf_file, preload=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original sampling frequency: 256.0 Hz\n",
            "  Number of channels: 23\n",
            "  Duration: 60.00 minutes\n",
            "  Applied Common Average Reference.\n",
            "  Applied bandpass filter (0.5-45 Hz).\n",
            "  Downsampled to 100.0 Hz.\n",
            "\n",
            "Processing file 5/6: chb01_15.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2891246402.py:37: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(edf_file, preload=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original sampling frequency: 256.0 Hz\n",
            "  Number of channels: 23\n",
            "  Duration: 60.00 minutes\n",
            "  Applied Common Average Reference.\n",
            "  Applied bandpass filter (0.5-45 Hz).\n",
            "  Downsampled to 100.0 Hz.\n",
            "\n",
            "Processing file 6/6: chb01_16.edf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2891246402.py:37: RuntimeWarning: Channel names are not unique, found duplicates for: {'T8-P8'}. Applying running numbers for duplicates.\n",
            "  raw = mne.io.read_raw_edf(edf_file, preload=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Original sampling frequency: 256.0 Hz\n",
            "  Number of channels: 23\n",
            "  Duration: 60.00 minutes\n",
            "  Applied Common Average Reference.\n",
            "  Applied bandpass filter (0.5-45 Hz).\n",
            "  Downsampled to 100.0 Hz.\n",
            "\n",
            "Finished preprocessing 6 files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f89552d",
        "outputId": "d2316693-39a6-4585-a459-6f14761fdb13"
      },
      "source": [
        "import mne\n",
        "print(f\"MNE-Python version: {mne.__version__}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MNE-Python version: 1.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95d50c76",
        "outputId": "116cc908-9751-43a2-b5ee-6f67d3713032"
      },
      "source": [
        "print(ica_cleaned_fif_paths)\n",
        "print(f\"Total ICA-cleaned .fif files saved: {len(ica_cleaned_fif_paths)}\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/unnamed_raw_0_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/unnamed_raw_1_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/unnamed_raw_2_ica_cleaned.fif']\n",
            "Total ICA-cleaned .fif files saved: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b01ffa6b",
        "outputId": "ca0153c4-cbd6-46dd-afaa-6a7e1080d350"
      },
      "source": [
        "from mne.preprocessing import ICA\n",
        "\n",
        "\n",
        "processed_data_dir = '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed'\n",
        "os.makedirs(processed_data_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "ica_cleaned_fif_paths = []\n",
        "\n",
        "\n",
        "if preprocessed_raw_objects:\n",
        "    print(f\"\\nApplying ICA to {len(preprocessed_raw_objects)} preprocessed Raw objects and saving them...\")\n",
        "    for i, raw_obj in enumerate(preprocessed_raw_objects):\n",
        "        # Use the description set in the previous step, or a generic name if unavailable\n",
        "        original_filename = raw_obj.info['description'] if raw_obj.info['description'] else f'unnamed_raw_{i}'\n",
        "        output_fif_path = os.path.join(processed_data_dir, f'{original_filename}_ica_cleaned.fif')\n",
        "\n",
        "        # Check if ICA-cleaned file already exists to avoid reprocessing\n",
        "        if os.path.exists(output_fif_path):\n",
        "            print(f\"  Skipping ICA for {original_filename} as {output_fif_path} already exists.\")\n",
        "\n",
        "            continue\n",
        "\n",
        "        print(f\"  Processing raw object {i+1}/{len(preprocessed_raw_objects)}: {original_filename}\")\n",
        "        try:\n",
        "\n",
        "            n_components_ica = min(20, len(raw_obj.ch_names))\n",
        "            ica = ICA(n_components=n_components_ica, random_state=99, verbose=False)\n",
        "\n",
        "\n",
        "            ica.fit(raw_obj)\n",
        "\n",
        "\n",
        "            ica_cleaned_raw = ica.apply(raw_obj.copy(), exclude=ica.exclude, verbose=False)\n",
        "            print(f\"    ICA applied. Original channels: {len(raw_obj.ch_names)}, ICA components: {ica.n_components_}, Excluded components: {len(ica.exclude)}\")\n",
        "\n",
        "\n",
        "            ica_cleaned_raw.set_meas_date(None)\n",
        "\n",
        "\n",
        "\n",
        "            ica_cleaned_raw.save(output_fif_path, overwrite=True, verbose=False)\n",
        "            print(f\"    Saved ICA-cleaned data to: {output_fif_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error applying ICA to raw object {i+1} ({original_filename}): {e}\")\n",
        "\n",
        "\n",
        "ica_cleaned_fif_paths = [os.path.join(processed_data_dir, f) for f in os.listdir(processed_data_dir) if f.endswith('_ica_cleaned.fif') or f.endswith('_ica_cleaned.fif.gz')]\n",
        "\n",
        "if ica_cleaned_fif_paths:\n",
        "    print(f\"\\nFinished ICA cleaning and saving. Total {len(ica_cleaned_fif_paths)} ICA-cleaned .fif files found on disk.\")\n",
        "    print(\"List of ICA-cleaned .fif files:\", ica_cleaned_fif_paths)\n",
        "else:\n",
        "    print(\"\\nNo ICA-cleaned .fif files were found on disk. Please ensure EDF files are present in the raw data directory and processed in previous steps, and ICA runs successfully.\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying ICA to 6 preprocessed Raw objects and saving them...\n",
            "  Processing raw object 1/6: chb01_12\n",
            "    ICA applied. Original channels: 23, ICA components: 20, Excluded components: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2294146930.py:43: RuntimeWarning: This filename (/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_12_ica_cleaned.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  ica_cleaned_raw.save(output_fif_path, overwrite=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Saved ICA-cleaned data to: /content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_12_ica_cleaned.fif\n",
            "  Processing raw object 2/6: chb01_11\n",
            "    ICA applied. Original channels: 23, ICA components: 20, Excluded components: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2294146930.py:43: RuntimeWarning: This filename (/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_11_ica_cleaned.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  ica_cleaned_raw.save(output_fif_path, overwrite=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Saved ICA-cleaned data to: /content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_11_ica_cleaned.fif\n",
            "  Processing raw object 3/6: chb01_13\n",
            "    ICA applied. Original channels: 23, ICA components: 20, Excluded components: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2294146930.py:43: RuntimeWarning: This filename (/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_13_ica_cleaned.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  ica_cleaned_raw.save(output_fif_path, overwrite=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Saved ICA-cleaned data to: /content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_13_ica_cleaned.fif\n",
            "  Processing raw object 4/6: chb01_14\n",
            "    ICA applied. Original channels: 23, ICA components: 20, Excluded components: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2294146930.py:43: RuntimeWarning: This filename (/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_14_ica_cleaned.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  ica_cleaned_raw.save(output_fif_path, overwrite=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Saved ICA-cleaned data to: /content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_14_ica_cleaned.fif\n",
            "  Processing raw object 5/6: chb01_15\n",
            "    ICA applied. Original channels: 23, ICA components: 20, Excluded components: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2294146930.py:43: RuntimeWarning: This filename (/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_15_ica_cleaned.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  ica_cleaned_raw.save(output_fif_path, overwrite=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Saved ICA-cleaned data to: /content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_15_ica_cleaned.fif\n",
            "  Processing raw object 6/6: chb01_16\n",
            "    ICA applied. Original channels: 23, ICA components: 20, Excluded components: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2294146930.py:43: RuntimeWarning: This filename (/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_16_ica_cleaned.fif) does not conform to MNE naming conventions. All raw files should end with raw.fif, raw_sss.fif, raw_tsss.fif, _meg.fif, _eeg.fif, _ieeg.fif, raw.fif.gz, raw_sss.fif.gz, raw_tsss.fif.gz, _meg.fif.gz, _eeg.fif.gz or _ieeg.fif.gz\n",
            "  ica_cleaned_raw.save(output_fif_path, overwrite=True, verbose=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    Saved ICA-cleaned data to: /content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_16_ica_cleaned.fif\n",
            "\n",
            "Finished ICA cleaning and saving. Total 16 ICA-cleaned .fif files found on disk.\n",
            "List of ICA-cleaned .fif files: ['/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_08_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_01_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_02_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_09_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_03_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_10_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_04_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_05_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_07_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_06_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_12_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_11_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_13_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_14_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_15_ica_cleaned.fif', '/content/drive/MyDrive/NeuroFedMeta/data/Raw_CHBMIT/processed/chb01_16_ica_cleaned.fif']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f5cca7d"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1. Define segmentation parameters\n",
        "segment_duration = 5 # seconds\n",
        "\n",
        "# 2. Initialize an empty list to store the extracted data from each segment\n",
        "segmented_data_for_causal_analysis = []\n",
        "\n",
        "# 3. Iterate through each ICA-cleaned .fif file path\n",
        "if 'ica_cleaned_fif_paths' in locals() and ica_cleaned_fif_paths:\n",
        "    print(f\"\\nSegmenting data from {len(ica_cleaned_fif_paths)} ICA-cleaned .fif files...\")\n",
        "    for i, fif_path in enumerate(ica_cleaned_fif_paths):\n",
        "        filename = os.path.basename(fif_path)\n",
        "        print(f\"  Segmenting file {i+1}/{len(ica_cleaned_fif_paths)}: {filename}\")\n",
        "        try:\n",
        "            # Load the ICA-cleaned Raw object from the .fif file\n",
        "            raw_obj = mne.io.read_raw_fif(fif_path, preload=True, verbose=False)\n",
        "\n",
        "            # 4. Create non-overlapping epochs (segments) of the defined duration\n",
        "            epochs = mne.make_fixed_length_epochs(raw_obj, duration=segment_duration, overlap=0, preload=True, verbose=False)\n",
        "            print(f\"    Created {len(epochs)} epochs, each {segment_duration} seconds long.\")\n",
        "\n",
        "            # 5. Extract the numerical data from each epoch and prepare for causal inference\n",
        "            epochs_data = epochs.get_data(picks='eeg')\n",
        "\n",
        "            n_epochs, n_channels, n_times = epochs_data.shape\n",
        "            reshaped_epochs_data = epochs_data.reshape(n_epochs, n_channels * n_times)\n",
        "\n",
        "            segmented_data_for_causal_analysis.append(reshaped_epochs_data)\n",
        "\n",
        "            # Explicitly delete objects to free memory after processing a chunk\n",
        "            del epochs, raw_obj\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  Error segmenting file {i+1} ({filename}): {e}\")\n",
        "\n",
        "    # Concatenate all segmented data if multiple files were processed\n",
        "    if segmented_data_for_causal_analysis:\n",
        "        all_segmented_data = np.vstack(segmented_data_for_causal_analysis)\n",
        "        print(f\"\\nFinished segmentation. Processed {len(ica_cleaned_fif_paths)} files and created a total of {all_segmented_data.shape[0]} segments.\")\n",
        "        print(f\"Shape of combined segmented data for causal analysis: {all_segmented_data.shape}\")\n",
        "    else:\n",
        "        print(\"No segments were successfully created for causal analysis.\")\n",
        "else:\n",
        "    print(\"\\nNo ICA-cleaned .fif file paths available for segmentation. Please ensure ICA cleaning and saving steps ran successfully.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a87f74f"
      },
      "source": [
        "import h5py\n",
        "import os\n",
        "\n",
        "# 1. Check if segmented data exists\n",
        "if 'all_segmented_data' in locals() and all_segmented_data.size > 0:\n",
        "    data_to_save = all_segmented_data\n",
        "    print(f\"Data to save found with shape: {data_to_save.shape}\")\n",
        "elif segmented_data_for_causal_analysis:\n",
        "\n",
        "    data_to_save = np.vstack(segmented_data_for_causal_analysis)\n",
        "    print(f\"Data to save found in list form with shape: {data_to_save.shape}\")\n",
        "else:\n",
        "    print(\"No segmented data available to save. Please ensure previous steps ran successfully.\")\n",
        "    data_to_save = None\n",
        "\n",
        "if data_to_save is not None:\n",
        "    # 2. Define filename and path\n",
        "    processed_data_dir = '/content/data/processed/'\n",
        "    os.makedirs(processed_data_dir, exist_ok=True)\n",
        "    output_filename = os.path.join(processed_data_dir, 'segmented_eeg_data.h5')\n",
        "\n",
        "    # 4. Use h5py.File() to create or open an HDF5 file\n",
        "    with h5py.File(output_filename, 'w') as f:\n",
        "        # 5. Save the NumPy array as a dataset within the HDF5 file with compression\n",
        "        f.create_dataset('eeg_segments', data=data_to_save, compression=\"gzip\", compression_opts=9)\n",
        "\n",
        "    print(f\"Successfully saved segmented EEG data to: {output_filename}\")\n",
        "    print(f\"Saved data shape: {data_to_save.shape}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b26af63e40e24a59a20ac00b40efe4a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60d2933769bf467ebb5566513d795b20",
              "IPY_MODEL_7b22f780112541f4b83887883aacde14",
              "IPY_MODEL_24d14248214e42659246e9e11a3273fd"
            ],
            "layout": "IPY_MODEL_db0b386e79384e7d926f7f51dcc26ee7"
          }
        },
        "60d2933769bf467ebb5566513d795b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91478f95a9f84f35aa391f92e1c3c9fe",
            "placeholder": "",
            "style": "IPY_MODEL_127f23687699495e884e3b4b59153c16",
            "value": "Depth=8,workingonnode21:100%"
          }
        },
        "7b22f780112541f4b83887883aacde14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cd4aede489049c7a4e1eaf9aea4d11e",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8084bec3f659430f9b2e1400207adabd",
            "value": 22
          }
        },
        "24d14248214e42659246e9e11a3273fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff82a00ecb1646ce9b0a05bd651f3e79",
            "placeholder": "",
            "style": "IPY_MODEL_022ecb026fcd4654a80fe46b566fb01c",
            "value": "22/22[00:00&lt;00:00,960.26it/s]"
          }
        },
        "db0b386e79384e7d926f7f51dcc26ee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91478f95a9f84f35aa391f92e1c3c9fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "127f23687699495e884e3b4b59153c16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0cd4aede489049c7a4e1eaf9aea4d11e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8084bec3f659430f9b2e1400207adabd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff82a00ecb1646ce9b0a05bd651f3e79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "022ecb026fcd4654a80fe46b566fb01c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec985a930caf482ebbdfdf6615e67938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4ba767756164253be11a16b8f1555d4",
              "IPY_MODEL_420844059e00411992a75d068ace00da",
              "IPY_MODEL_3c8069123e7c41d7aa8766091fa8f2fa"
            ],
            "layout": "IPY_MODEL_1e42ab823329465285f8f15d6b71090b"
          }
        },
        "e4ba767756164253be11a16b8f1555d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5bf21bcfc1a54ce999ac66f5b806dd7c",
            "placeholder": "",
            "style": "IPY_MODEL_e6cc8cf1fcda4318830f212f8985056e",
            "value": "Depth=8,workingonnode21:100%"
          }
        },
        "420844059e00411992a75d068ace00da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7893d85e3b33441b885d9bb451fe8f01",
            "max": 22,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a004f83bd7ac418f86226ca04a80c754",
            "value": 22
          }
        },
        "3c8069123e7c41d7aa8766091fa8f2fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc823ba0c84d4330b6d0ca2b92504029",
            "placeholder": "",
            "style": "IPY_MODEL_ab0f6027a19047ce80ce72e8c8247791",
            "value": "22/22[00:00&lt;00:00,699.45it/s]"
          }
        },
        "1e42ab823329465285f8f15d6b71090b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5bf21bcfc1a54ce999ac66f5b806dd7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6cc8cf1fcda4318830f212f8985056e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7893d85e3b33441b885d9bb451fe8f01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a004f83bd7ac418f86226ca04a80c754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cc823ba0c84d4330b6d0ca2b92504029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab0f6027a19047ce80ce72e8c8247791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}